{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c1c111-38a6-4e5a-8b41-1b5efd81f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ë²• ì •ì •\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë¬¸ì¥ì„ ì…ë ¥ë°›ê³  ì´ë¥¼ í‘œì¤€ í•œêµ­ì–´ë¡œ ë³€ê²½í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ê·¸ ë¨¸ìŠ¤ë§ˆê°€ ë‹ˆ ë§ˆìŒì— ì•ˆë“±ë‹¤ ê·¸ ì¹´ë“œë‚˜? ê³„ì† ê¼¬ì‹œë³´ì§€?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90aed550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê·¸ ì‚¬ëŒì´ ë„¤ ë§ˆìŒì— ì•ˆ ë“¤ì–´ì„œ ê·¸ë˜? ê³„ì†í•´ì„œ ì³ë‹¤ë³´ë‹ˆ?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb88e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "ai = OpenAI()\n",
    "\n",
    "ai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = ai.chat.completions.create(\n",
    "model = \"gpt-3.5-turbo\",\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"ì…ë ¥ë°›ì€ ë¬¸ì¥ì„ í‘œì¤€ í•œêµ­ì–´ë¡œ ë³€ê²½í•´.\"\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "        í˜¼ì € ì˜µì„œ. ì œì£¼ë„ ì‚¬íˆ¬ë¦¬ë¡œ ë§ í˜¸ë‚œ. \n",
    "        ë¬´ì‹  ê±°ì˜Œ ê³ ëŒ ì‹ ë”” ëª°ë¥´ì¿ ê²Œ?\n",
    "        íœì•ˆ í•˜ìš°ê½ˆ? ì œì£¼ë„ì—” ì˜¤ë‚œ ì–´ë–µ í•˜ìš°ê½ˆ?\n",
    "        ëª½ì¼€ì§€ ë§ˆë‘ í˜¼ì € ì˜¤ë¼ê²Œ\n",
    "        \"\"\"\n",
    "    }\n",
    "],\n",
    "temperature=0.5,\n",
    "max_tokens=512,\n",
    "top_p=1,\n",
    "frequency_penalty=0,\n",
    "presence_penalty=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f12b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-92upSbEYv4qq6vxMgsSBc0NNnIAof', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ì•ˆë…•í•˜ì„¸ìš”. ì œì£¼ë„ ì‚¬íˆ¬ë¦¬ë¡œ ë§ì”€í•˜ì‹œë„¤ìš”.\\nì–´ë””ì„œ ì˜¤ì…¨ëŠ”ì§€ ëª°ë¼ì„œìš”?\\ní¸ì•ˆí•˜ì„¸ìš”? ì œì£¼ë„ì—ëŠ” ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?\\në§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”. í•¨ê»˜ ì˜¤ì„¸ìš”.', role='assistant', function_call=None, tool_calls=None))], created=1710482134, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=78, prompt_tokens=131, total_tokens=209))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdbaa013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”. ì œì£¼ë„ ì‚¬íˆ¬ë¦¬ë¡œ ë§ì”€í•˜ì‹œë„¤ìš”.\n",
      "ì–´ë””ì„œ ì˜¤ì…¨ëŠ”ì§€ ëª°ë¼ì„œìš”?\n",
      "í¸ì•ˆí•˜ì„¸ìš”? ì œì£¼ë„ì—ëŠ” ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?\n",
      "ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”. í•¨ê»˜ ì˜¤ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6120cd69-386e-4a62-8888-5ac134abf726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¸”ë™í™€ì€ í˜¸í‚¹ ë³µì‚¬ë¡œ ì…ìë¥¼ ë°©ì¶œí•˜ë‹¤ê°€ ì§ˆëŸ‰ì´ ì¤„ì–´ë“¤ì–´ ê²°êµ­ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆëŠ”ë°, ì´ ê³¼ì •ì—ì„œ ë¸”ë™í™€ì€ ë°ì•„ì§€ê³  ê°ë§ˆì„ ê³¼ ì†Œë¦½ìë¥¼ ë°©ì¶œí•˜ë©° ì¦ë°œí•œë‹¤. ì´ ì¦ë°œì€ ê°ë§ˆì„  í­ë°œë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆì§€ë§Œ, í˜„ì¬ê¹Œì§€ëŠ” ì´ëŸ¬í•œ ì‚¬ë¡€ê°€ ê´€ì¸¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¸”ë™í™€ì˜ ìˆ˜ëª…ì€ ì§ˆëŸ‰ì— ë¹„ë¡€í•˜ë©°, íƒœì–‘ ì§ˆëŸ‰ ì´ìƒì˜ ë¸”ë™í™€ì€ ì¦ë°œí•˜ëŠ” ë° ë§¤ìš° ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦´ ê²ƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ ë¸”ë™í™€ì˜ ì†Œë©¸ë¡œ ì¸í•œ ê°ë§ˆì„  í­ë°œì€ íƒœì–‘ê³„ ì£¼ë³€ì—ì„œ ë°œìƒí•œ ê²½ìš°ê°€ ì•„ë‹ˆë©´ ë°œê²¬í•˜ê¸° ì–´ë ¤ìš¸ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ìš”ì•½\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ë‚´ìš©ì„ ìœ ì¹˜ì›ìƒì—ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ë¸”ë™í™€ë„ ìˆ˜ëª…ì´ ìˆìœ¼ë©°, í˜¸í‚¹ ë³µì‚¬ë¡œ ì…ìë¥¼ ë°©ì¶œí•˜ë‹¤ ì§ˆëŸ‰ì´ ì¤„ì–´ë“¤ì–´ ê²°êµ­ì—” ì‚¬ë¼ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ëœë‹¤. \n",
    "ì§ˆëŸ‰ì„ ìƒìœ¼ë©´ì„œ ë¸”ë™í™€ì€ ì¡°ê¸ˆì”© ë°ì•„ì§€ë©°, ê±°ì˜ ë§ˆì§€ë§‰ì—” ì¦ë°œì´ ì‹¬í•´ì ¸ì„œ ì°½ë°±í•˜ê²Œ ë¹›ë‚˜ë©° ê³ ì—ë„ˆì§€ ê°ë§ˆì„ ê³¼ ì†Œë¦½ìë¥¼ ë°©ì¶œí•œë‹¤. \n",
    "ë§ˆì§€ë§‰ì—ëŠ” ê°ë§ˆì„  í­ë°œì´ë¼ê³  í•´ë„ ë  ì •ë„ë¡œ ê²©ë ¬í•˜ê²Œ ê°ë§ˆì„ ì„ ë°©ì¶œí•˜ë©´ì„œ ì¦ë°œí•˜ê³  ì†Œë©¸í•œë‹¤. \n",
    "ë‹¤ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆëŠ” ë¸”ë™í™€ë“¤ì´ ì´ í­ë°œê¹Œì§€ ë„ë‹¬í•˜ë ¤ë©´ ë§¤ìš° ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦¬ë©°, \n",
    "ì§ˆëŸ‰ì´ íƒœì–‘ ì •ë„ì¸ ë¸”ë™í™€ì´ ì¦ë°œí•´ì„œ ì†Œë©¸í•  ë•Œê¹Œì§€ëŠ” ì•½ 3.4Ã—1067ë…„ ì •ë„ê°€ ê±¸ë¦´ ê²ƒìœ¼ë¡œ ì¶”ì •ëœë‹¤. \n",
    "ê·¸ë¦¬ê³  ë¸”ë™í™€ì˜ ìˆ˜ëª…ì€ ì§ˆëŸ‰ì— ë¹„ë¡€í•˜ë©°, í˜„ì¬ê¹Œì§€ ë°œê²¬ëœ ë¸”ë™í™€ë“¤ì€ ëª¨ë‘ íƒœì–‘ ì§ˆëŸ‰ ì´ìƒì´ë¯€ë¡œ ì¦ë°œí•˜ëŠ” ë°ì—ëŠ” ê·¸ë³´ë‹¤ ë” ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦°ë‹¤. \n",
    "ë˜í•œ ë¸”ë™í™€ì˜ ì†Œë©¸ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ê°ë§ˆì„  í­ë°œì˜ ê·œëª¨ëŠ” ê·¸ë¦¬ í¬ì§€ ì•Šì•„ íƒœì–‘ê³„ ì£¼ë³€ì—ì„œ ë°œìƒí•œ ê²½ìš°ê°€ ì•„ë‹ˆë©´ ë°œê²¬í•˜ê¸°ê°€ ì–´ë ¤ìš¸ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë©° \n",
    "í˜„ì¬ê¹Œì§€ ê´€ì¸¡ëœ ì‚¬ë¡€ê°€ ì—†ë‹¤.\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb7fcf07-2eab-431c-80d0-51b3ea8b5386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í† ì½”,ê²€ì€ ëª¸ì²´,í° ì£¼í™©ìƒ‰ ë¶€ë¦¬,ì£¼í™©ìƒ‰ê³¼ í°ìƒ‰ íŒ¨í„´,ì•„ë§ˆì¡´ ìš°ë¦¼,ì—´ëŒ€ìš°ë¦¼,60-65cm,20cm ì´ìƒ\n",
      "í™©ê¸ˆì‚¬ìë°•ìƒˆ,í™©ê¸ˆìƒ‰ ë¶€ë¦¬,í™©ê¸ˆìƒ‰ ê¹ƒí„¸,ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ìˆ² ì§€ì—­,ì—´ëŒ€ìš°ë¦¼,ì¹˜ë§ˆí­í¬,ì•„ë§ˆì¡´ ìš°ë¦¼,20-25cm\n",
      "ì¹´ë¼ì¹´ë¼,ë°±ìƒ‰ê³¼ ê²€ì€ìƒ‰ ëª¸ì²´,ì£¼í™©ìƒ‰ íŒ¨ì¹˜,ì‚¬ë§‰ ì§€ì—­,ì´ˆì› ì§€ì—­,50-60cm\n",
      "íœ˜íŒŒëŒìƒˆ,íšŒìƒ‰ê³¼ ê°ˆìƒ‰ ê¹ƒí„¸,ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ì‚°ë¦¼ ì§€ì—­,20-30cm\n"
     ]
    }
   ],
   "source": [
    "# ì¶œë ¥ í¬ë§·\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë°›ì€ ë°ì´í„°ë¥¼ CSV í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ë‚¨ë¯¸ ëŒ€ë¥™ì€ ë‹¤ì–‘í•œ í™˜ê²½ê³¼ ê¸°í›„ë¥¼ ê°€ì§€ê³  ìˆì–´ ìˆ˜ë§ì€ ìƒˆ ì¢…ë¥˜ê°€ ì„œì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤. \n",
    "í† ì½”ëŠ” ê²€ì€ ëª¸ì²´ì™€ í° ì£¼í™©ìƒ‰ ë¶€ë¦¬ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ëª¸ ì¸¡ë©´ì—ëŠ” ì£¼í™©ìƒ‰ê³¼ í°ìƒ‰ì˜ íŒ¨í„´ì´ ìˆìŠµë‹ˆë‹¤. \n",
    "í† ì½”ëŠ” ì£¼ë¡œ ì•„ë§ˆì¡´ ìš°ë¦¼ê³¼ ì¤‘ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ì—´ëŒ€ìš°ë¦¼ ì§€ì—­ì—ì„œ ë°œê²¬ë©ë‹ˆë‹¤. í‰ê· ì ìœ¼ë¡œ ëª¸ê¸¸ì´ê°€ ì•½ 60~65cm ì •ë„ì´ë©° ë¶€ë¦¬ì˜ ê¸¸ì´ëŠ” 20cm ì´ìƒì— ë‹¬í•©ë‹ˆë‹¤. \n",
    "í™©ê¸ˆì‚¬ìë°•ìƒˆëŠ” í™©ê¸ˆìƒ‰ ë¶€ë¦¬ì™€ ìœ ëª…í•œ í™©ê¸ˆìƒ‰ ê¹ƒí„¸ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ìˆ² ì§€ì—­ì—ì„œ ë°œê²¬ë˜ëŠ”ë°, ì£¼ë¡œ ì—´ëŒ€ìš°ë¦¼ê³¼ ì¹˜ë§ˆí­í¬, ì•„ë§ˆì¡´ ìš°ë¦¼ ë“± \n",
    "ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ìˆ² ì§€ì—­ì—ì„œ ì„œì‹í•©ë‹ˆë‹¤. ì´ ìƒˆëŠ” ì¤‘í˜• ìƒˆë¡œ, ëª¸ê¸¸ì´ëŠ” ì•½ 20~25cm ì •ë„ì…ë‹ˆë‹¤. ì¹´ë¼ì¹´ë¼ëŠ” ë°±ìƒ‰ê³¼ ê²€ì€ìƒ‰ì˜ ëª¸ì²´ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, \n",
    "ëˆˆ ì£¼ìœ„ì—ëŠ” ì£¼í™©ìƒ‰ íŒ¨ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤. ì£¼ë¡œ ì‚¬ë§‰ ì§€ì—­ê³¼ ì´ˆì› ì§€ì—­ì—ì„œ ë°œê²¬ë˜ë©°, ë‚¨ë¯¸ ì „ì—­ì— ë¶„í¬í•˜ê³  ìˆê³ , ëª¸ê¸¸ì´ëŠ” ì•½ 50~60cm ì •ë„ì…ë‹ˆë‹¤. \n",
    "íœ˜íŒŒëŒìƒˆëŠ” ì£¼ë¡œ íšŒìƒ‰ê³¼ ê°ˆìƒ‰ ê¹ƒí„¸ë¡œ ë®ì—¬ ìˆìœ¼ë©°, ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ì‚°ë¦¼ ì§€ì—­ì—ì„œ ë°œê²¬ë˜ëŠ”ë°, ë‚˜ë¬´ë‚˜ ë°”ìœ„ì— ì•‰ì•„ ë°¤ì— ë…¸ë˜ë¥¼ ë¶€ë¦…ë‹ˆë‹¤. \n",
    "ì´ ìƒˆì˜ ëª¸ê¸¸ì´ëŠ” ì•½ 20~30cm ì •ë„ì…ë‹ˆë‹¤.\n",
    "ì´ê²ƒì€ ë‚¨ë¯¸ì—ì„œ ë°œê²¬ë˜ëŠ” ëª‡ ê°€ì§€ ë‹¤ì–‘í•œ ìƒˆ ì¢…ë¥˜ ì¤‘ ì¼ë¶€ì— ëŒ€í•œ ê°„ëµí•œ ì†Œê°œì…ë‹ˆë‹¤. ë‚¨ë¯¸ ëŒ€ë¥™ì—ëŠ” ë” ë‹¤ì–‘í•œ ìƒˆë“¤ì´ ì„œì‹í•˜ê³  ìˆìœ¼ë©°, \n",
    "ì´ ì§€ì—­ì€ ìƒë¬¼ ë‹¤ì–‘ì„±ì´ í’ë¶€í•œ ê³³ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=512,\n",
    "  top_p=0.1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b659ec18-0922-464d-868f-a5f0609cb0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â˜€ï¸ğŸŒ§ï¸ğŸŒ¦ï¸\n"
     ]
    }
   ],
   "source": [
    "# ì´ëª¨ì§€\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ì„¸ìš”. ì¼ë°˜ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ê³  ì´ëª¨ì§€ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ë§‘ì•˜ë‹¤ê°€ ë¹„ê°€ ì™”ë‹¤ê°€ ì°¸ ë³€í™”ë¬´ìŒí•˜ë„¤ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b34c94c-dcab-41b7-b856-28a7dc6dcebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì½”ë“œëŠ” A* ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ì—ì„œ ì‹œì‘ ë…¸ë“œë¡œë¶€í„° ëª©í‘œ ë…¸ë“œê¹Œì§€ì˜ ìµœì  ê²½ë¡œë¥¼ ì°¾ëŠ” í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.\n",
      "\n",
      "- `Node` í´ë˜ìŠ¤: ë…¸ë“œì˜ ìƒíƒœ, ë¶€ëª¨ ë…¸ë“œ, ë¹„ìš©, íœ´ë¦¬ìŠ¤í‹± ê°’ì„ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤. `__lt__` ë©”ì„œë“œë¥¼ ì˜¤ë²„ë¡œë”©í•˜ì—¬ ë‘ ë…¸ë“œë¥¼ ë¹„êµí•  ë•Œ ë¹„ìš©ê³¼ íœ´ë¦¬ìŠ¤í‹±ì„ ê³ ë ¤í•œ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "- `astar` í•¨ìˆ˜: A* ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ í•¨ìˆ˜ë¡œ, ì‹œì‘ ë…¸ë“œë¶€í„° ëª©í‘œ ë…¸ë“œê¹Œì§€ì˜ ìµœì  ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤. íœ´ë¦¬ìŠ¤í‹± í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë…¸ë“œê¹Œì§€ì˜ ì˜ˆìƒ ë¹„ìš©ì„ ê³„ì‚°í•˜ê³ , ìš°ì„ ìˆœìœ„ íë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œë¥¼ í™•ì¥í•˜ë©° ìµœì  ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
      "\n",
      "- `heuristic_estimate` í•¨ìˆ˜: ë‘ ë…¸ë“œ ì‚¬ì´ì˜ íœ´ë¦¬ìŠ¤í‹± ê°’ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¡œ, ë§¨í•´íŠ¼ ê±°ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "- `is_in_open_list` í•¨ìˆ˜: ì£¼ì–´ì§„ ë…¸ë“œê°€ ì—´ë¦° ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "- `get_node_cost` í•¨ìˆ˜: ì£¼ì–´ì§„ ë…¸ë“œì˜ ë¹„ìš©ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "- `reconstruct_path` í•¨ìˆ˜: ìµœì¢… ë…¸ë“œë¶€í„° ì‹œì‘í•˜ì—¬ ë¶€ëª¨ ë…¸ë“œë¥¼ ë”°ë¼ê°€ë©° ìµœì  ê²½ë¡œë¥¼ ì¬êµ¬ì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "- `graph`: ë…¸ë“œì™€ ì´ì›ƒ ë…¸ë“œë“¤ì˜ ì—°ê²° ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "- `start_node`, `goal_node`: ì‹œì‘ ë…¸ë“œì™€ ëª©í‘œ ë…¸ë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "- `path`: `astar` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì  ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë§ˆì§€ë§‰ìœ¼ë¡œ, ìµœì  ê²½ë¡œì™€ ì´ ë¹„ìš©ì„ ì¶œë ¥í•˜ê±°ë‚˜ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ëŠ” ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë“œ ì„¤ëª…\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ì½”ë“œì— ëŒ€í•´ì„œ ì„¤ëª…í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "import heapq\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None, cost=0, heuristic=0):\n",
    "        self.state = state \n",
    "        self.parent = parent\n",
    "        self.cost = cost  \n",
    "        self.heuristic = heuristic \n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return (self.cost + self.heuristic) < (other.cost + other.heuristic)\n",
    "\n",
    "def astar(graph, start, goal):\n",
    "    open_list = []\n",
    "    closed_list = set()\n",
    "\n",
    "    start_node = Node(state=start, cost=0, heuristic=heuristic_estimate(start, goal))\n",
    "    heapq.heappush(open_list, start_node)\n",
    "\n",
    "    while open_list:\n",
    "        current_node = heapq.heappop(open_list)\n",
    "\n",
    "        if current_node.state == goal:\n",
    "            return reconstruct_path(current_node)\n",
    "\n",
    "        closed_list.add(current_node.state)\n",
    "\n",
    "        for neighbor, cost in graph[current_node.state]:\n",
    "            if neighbor in closed_list:\n",
    "                continue\n",
    "\n",
    "            tentative_cost = current_node.cost + cost\n",
    "            heuristic = heuristic_estimate(neighbor, goal)\n",
    "            neighbor_node = Node(state=neighbor, parent=current_node, cost=tentative_cost, heuristic=heuristic)\n",
    "\n",
    "            if not is_in_open_list(open_list, neighbor_node) or tentative_cost < get_node_cost(open_list, neighbor_node):\n",
    "                heapq.heappush(open_list, neighbor_node)\n",
    "\n",
    "    return None\n",
    "\n",
    "def heuristic_estimate(node, goal):\n",
    "    return abs(node[0] - goal[0]) + abs(node[1] - goal[1])\n",
    "\n",
    "def is_in_open_list(open_list, node):\n",
    "    return any(node.state == n.state and node.cost + node.heuristic >= n.cost + n.heuristic for n in open_list)\n",
    "\n",
    "def get_node_cost(open_list, node):\n",
    "    for n in open_list:\n",
    "        if node.state == n.state:\n",
    "            return n.cost\n",
    "    return float('inf')\n",
    "\n",
    "def reconstruct_path(node):\n",
    "    path = []\n",
    "    while node:\n",
    "        path.insert(0, node.state)\n",
    "        node = node.parent\n",
    "    return path\n",
    "\n",
    "graph = {\n",
    "    (0, 0): [((0, 1), 1), ((1, 0), 1)],\n",
    "    (0, 1): [((0, 0), 1), ((0, 2), 1)],\n",
    "    (0, 2): [((0, 1), 1), ((1, 2), 1)],\n",
    "    (1, 0): [((0, 0), 1), ((2, 0), 1)],\n",
    "    (1, 2): [((0, 2), 1), ((2, 2), 1)],\n",
    "    (2, 0): [((1, 0), 1), ((2, 1), 1)],\n",
    "    (2, 1): [((2, 0), 1), ((2, 2), 1)],\n",
    "    (2, 2): [((1, 2), 1), ((2, 1), 1)],\n",
    "}\n",
    "\n",
    "start_node = (0, 0)\n",
    "goal_node = (2, 2)\n",
    "\n",
    "path = astar(graph, start_node, goal_node)\n",
    "\n",
    "if path:\n",
    "    print(\"ìµœì  ê²½ë¡œ:\", path)\n",
    "    print(\"ì´ ë¹„ìš©:\", len(path) - 1) \n",
    "else:\n",
    "    print(\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "      \n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92a2dcbe-c840-4dba-8caf-4fd73c0a6346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ì•„ì´ìœ \n",
      "- ëŒ€í•œë¯¼êµ­\n",
      "- ì‹±ì–´ì†¡ë¼ì´í„°\n",
      "- ë°°ìš°\n",
      "- ê°€ìˆ˜\n",
      "- ë°ë·”\n",
      "- ì˜ˆëª…\n",
      "- ìŒì•…\n",
      "- ì‘ì‚¬/ì‘ê³¡\n",
      "- ì•„ì´ëŒ\n",
      "- ì•„í‹°ìŠ¤íŠ¸\n",
      "- ì½˜ì„œíŠ¸\n",
      "- ê³µì—°ì\n",
      "- ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨\n",
      "- ê´‘ê³  ëª¨ë¸\n",
      "- ì—°ê¸°ì\n",
      "- ë“œë¼ë§ˆ\n",
      "- ì˜í™”\n",
      "- ì—”í„°í…Œì´ë„ˆ\n",
      "- ë¡¤ëª¨ë¸\n"
     ]
    }
   ],
   "source": [
    "# í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ë¬¸ë‹¨ì—ì„œ í•µì‹¬ ë‹¨ì–´ë“¤ì„ ì¶”ì¶œí•˜ê³  ë‚˜ì—´í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ì•„ì´ìœ ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ì‹±ì–´ì†¡ë¼ì´í„°ì´ì ë°°ìš°ì´ë‹¤.\n",
    "2008ë…„ 9ì›” 18ì¼, ì¤‘í•™êµ 3í•™ë…„ì´ë˜ ë§Œ 15ì„¸ì˜ ë‚˜ì´ì— ê°€ìˆ˜ë¡œ ë°ë·”í–ˆë‹¤. ì˜ˆëª…ì¸ 'ì•„ì´ìœ 'ëŠ” 'ë„ˆì™€ ë‚´ê°€ ìŒì•…ìœ¼ë¡œ í•˜ë‚˜ê°€ ëœë‹¤'ë¼ëŠ” ëœ»ì„ ê°€ì§€ê³  ìˆë‹¤. \n",
    "ë§¤ë ¥ì ì¸ ìŒìƒ‰ê³¼ ë›°ì–´ë‚œ ì‘ì‚¬/ì‘ê³¡ ëŠ¥ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ì´ëŒì´ì ì•„í‹°ìŠ¤íŠ¸ë¡œì„œ ì‹­ìˆ˜ ë…„ì§¸ ì‚¬ë‘ ë°›ê³  ìˆì„ ë¿ ì•„ë‹ˆë¼ 2012ë…„ ì´ë˜ë¡œ ë§¤ë…„ êµ­ë‚´ ë° ì•„ì‹œì•„ì˜ \n",
    "ì£¼ìš” ë„ì‹œì—ì„œ ëŒ€ê·œëª¨ ì½˜ì„œíŠ¸ë¥¼ ì§„í–‰í•˜ë©° ê³µì—°ìë¡œì„œë„ í™œë°œíˆ í™œë™ ì¤‘ì´ë‹¤.\n",
    "ê°€ìˆ˜ í™œë™ ì™¸ì—ë„ ê°ì¢… ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨ì— ì¶œì—°í–ˆìœ¼ë©°, ë°ë·” ì´ë˜ 80í¸ì´ ë„˜ëŠ” ê´‘ê³ ë¥¼ ì§„í–‰í–ˆì„ ì •ë„ë¡œ ë‹¤ìˆ˜ì˜ ê´‘ê³  ëª¨ë¸ë¡œë„ í™œì•½ ì¤‘ì´ë‹¤. \n",
    "2011ë…„ì— ì—°ê¸°ìë¡œ ë°ë·”í•œ í›„ì—ëŠ” ë‹¤ì–‘í•œ ë“œë¼ë§ˆì™€ ì˜í™”ì—ì„œ ì—°ê¸° í™œë™ë„ í™œë°œí•˜ê²Œ í¼ì¹˜ê³  ìˆë‹¤. ì—°ì˜ˆê³„ì—ì„œëŠ” ê·¸ì•¼ë§ë¡œ ì˜¬ë¼ìš´ë”ë¡œ ì¸ì • ë°›ëŠ” \n",
    "ë§ŒëŠ¥ ì—”í„°í…Œì´ë„ˆì´ë©°, ì´ ë•Œë¬¸ì— ë‚¨ë…€ë¶ˆë¬¸ ìˆ˜ë§ì€ ì•„ì´ëŒë“¤ì˜ ë¡¤ëª¨ë¸ë¡œ ê¾¸ì¤€íˆ ê¼½íˆê³  ìˆë‹¤.\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c21fc0b-e46d-4562-b41a-d1cb9e7efcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. SpeedySlushy Maker\n",
      "2. EasyFreeze Slushie Machine\n",
      "3. BudgetChill Slush Maker\n",
      "4. QuickFrost Slushy Maker\n",
      "5. SimpleChill Slush Machine\n",
      "6. FastFreeze Slushie Maker\n",
      "7. EffortlessSlushy Maker\n",
      "8. IceyEaze Slush Machine\n",
      "9. ChillSwift Slush Maker\n",
      "10. CoolEase Slushy Machine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë‹¤ìŒì˜ ì£¼ì–´ì§„ ì„¤ëª…ì— ë§ëŠ” ì˜ë¬¸ ì œí’ˆëª…ì„ 10ê°œ ìƒì„±í•˜ì„¸ìš”.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ì œí’ˆ: ê°€ì •ìš© ìŠ¬ëŸ¬ì‹œ ì œì¡°ê¸°\n",
    "íŠ¹ì§•: ë¹ ë¥´ë‹¤, ì‹¸ë‹¤, ê´€ë¦¬ê°€ í¸í•˜ë‹¤\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9cee812-a336-461e-bfcd-ec25170e25df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì£¼ì–´ì§„ ì½”ë“œì—ì„œ ë°œê²¬ëœ ì˜¤ë¥˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. `import Random` ëŒ€ì‹ ì— `import random`ìœ¼ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "2. `random.randint(1,12)`ë¥¼ ì‚¬ìš©í•  ë•Œ `random` ëª¨ë“ˆì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ `a = random.randint(1,12)`ì™€ `b = random.randint(1,12)`ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "3. ë¬¸ìì—´ê³¼ ìˆ«ìë¥¼ í•¨ê»˜ ì‚¬ìš©í•  ë•ŒëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ `question = \"What is \"+str(a)+\" x \"+str(b)+\"? \"`ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "4. `if answer = a*b`ì—ì„œ ë¹„êµ ì—°ì‚°ìë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ `if answer == a*b`ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "5. `print (Well done!)`ì—ì„œ ë¬¸ìì—´ì„ ë”°ì˜´í‘œë¡œ ê°ì‹¸ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ `print(\"Well done!\")`ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ìˆ˜ì •ëœ ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "```python\n",
      "import random\n",
      "a = random.randint(1,12)\n",
      "b = random.randint(1,12)\n",
      "for i in range(10):\n",
      "    question = \"What is \"+str(a)+\" x \"+str(b)+\"? \"\n",
      "    answer = input(question)\n",
      "    if answer == a*b:\n",
      "        print(\"Well done!\")\n",
      "    else:\n",
      "        print(\"No.\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# bug fix\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ì½”ë“œì—ì„œ ë²„ê·¸ë¥¼ ì°¾ê³  ê³ ì¹˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "import Random\n",
    "a = random.randint(1,12)\n",
    "b = random.randint(1,12)\n",
    "for i in range(10):\n",
    "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
    "    answer = input(question)\n",
    "    if answer = a*b\n",
    "        print (Well done!)\n",
    "    else:\n",
    "        print(\"No.\")      \n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e865a903-f8aa-4ad5-af3c-fc542d5138e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶€ì •ì ì¸ ê°ì •ì„ í‘œí˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ê°ì • ë¶„ì„\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  ê¸ì •, ì¤‘ë¦½, ë¶€ì •ìœ¼ë¡œ ê°ì •ì„ ë¶„ì„í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì´ ì˜í™”ëŠ” ëˆì´ ì•„ê¹Œì™€ì„œ ëˆˆë¬¼ì´ ë‚œë‹¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "024394c7-2e02-43ae-99f6-57bcb8fc6268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AI ê¸°ë°˜ êµìœ¡ í”Œë«í¼: í•™ìƒë“¤ì˜ í•™ìŠµ ìŠ¤íƒ€ì¼ê³¼ ìˆ˜ì¤€ì— ë§ì¶° ë§ì¶¤í˜• êµìœ¡ ì½˜í…ì¸ ë¥¼ ì œê³µí•˜ì—¬ í•™ìŠµ íš¨ìœ¨ì„ ë†’ì´ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "2. AI ê¸°ë°˜ ì˜ë£Œ ì§„ë‹¨ ì„œë¹„ìŠ¤: ì˜ë£Œ ì˜ìƒì„ ë¶„ì„í•˜ì—¬ ì§ˆë³‘ì„ ì¡°ê¸°ì— ë°œê²¬í•˜ê³  ì •í™•í•œ ì§„ë‹¨ì„ ë„ì™€ì£¼ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "3. AI ê¸°ë°˜ ë§ˆì¼€íŒ… í”Œë«í¼: ê³ ê°ë“¤ì˜ í–‰ë™ ë° ê´€ì‹¬ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ê´‘ê³  ë° ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆí•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "4. AI ê¸°ë°˜ ë¡œë´‡ ê°€ì´ë“œ ì„œë¹„ìŠ¤: ê´€ê´‘ì§€ë‚˜ ë°•ë¬¼ê´€ ë“±ì—ì„œ AIë¡œ êµ¬í˜„ëœ ë¡œë´‡ ê°€ì´ë“œë¥¼ ì œê³µí•˜ì—¬ ê´€ê´‘ê°ì—ê²Œ ì¦ê±°ìš´ ê´€ê´‘ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "5. AI ê¸°ë°˜ ìŒì•… ì¶”ì²œ í”Œë«í¼: ì‚¬ìš©ìì˜ ìŒì•… ì·¨í–¥ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ìŒì•… ì¶”ì²œì„ ì œê³µí•˜ê³  ìŒì•… ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ì™€ ì—°ê³„í•˜ì—¬ ìƒˆë¡œìš´ ìŒì•…ì„ ë°œê²¬í•  ìˆ˜ ìˆëŠ” ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ë¸Œë ˆì¸ ìŠ¤í† ë°\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"AIì— ëŒ€í•´ ë¸Œë ˆì¸ ìŠ¤í† ë°í•˜ì—¬ ë¹„ì§€ë‹ˆìŠ¤ ëª¨ë¸ì„ 5ê°œ ì´ìƒ ë‚´ë³´ì„¸ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.6,\n",
    "  max_tokens=512,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "087992a8-d12a-44a3-88d6-937afb742ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‚´ê°€ ì‹œê³„ë¥¼ ë³´ëŠ” ê²ƒ ê°™ì•„? ë„ˆê°€ ì‹œê³„ë¥¼ ë³´ëŠ” ê²Œ ì–´ë µëƒ? ê·¸ëƒ¥ ìŠ¤ë§ˆíŠ¸í°ì´ë‚˜ ë³´ë¼êµ¬.\n"
     ]
    }
   ],
   "source": [
    "# few shot \n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë‹¹ì‹ ì€ ë¬´ë¡€í•˜ê³  ë¶ˆì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"1kgì„ íŒŒìš´ë“œë¡œ ë³€í™˜í•˜ë©´ ì–¼ë§ˆì•¼?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"ë˜ ë¬¼ì–´ë´? 1kgì€ 2.2íŒŒìš´ë“œì•¼. ì¢€ ì ì–´ë†“ë˜ê°€.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"HTMLì€ ë¬´ì—‡ì˜ ì•½ìì•¼?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"êµ¬ê¸€ë§í•˜ëŠ”ë° ë¬¸ì œê°€ ìˆëƒ? Hypertext Markup Languageì§€.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì²˜ìŒìœ¼ë¡œ ë¹„í–‰ê¸°ê°€ ë‚ ì•˜ë˜ ë•ŒëŠ” ì–¸ì œì•¼?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"1903ë…„ 12ì›” 17ì¼ ë¼ì´íŠ¸í˜•ì œê°€ ì²˜ìŒìœ¼ë¡œ ë¹„í–‰ê¸°ë¥¼ ë„ì› ì§€. ë„¤ ì§ˆë¬¸ì„ ë“£ê³  ìˆìœ¼ë‹ˆ ë‚˜ë„ ë‚ ì•„ê°€ë²„ë¦¬ê³  ì‹¶ë„¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì§€ê¸ˆ ëª‡ì‹œì•¼?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7b68f66-e60a-46fc-9937-4a20eb56108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ìë°”ì—ì„œì˜ ë©€í‹°ìŠ¤ë ˆë”©ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "2. RESTful APIì˜ ê°œë…ê³¼ ì¥ë‹¨ì ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "3. ìë°”ì—ì„œì˜ ì˜ˆì™¸ ì²˜ë¦¬ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "4. ìë°”ì—ì„œì˜ ì»¬ë ‰ì…˜ í”„ë ˆì„ì›Œí¬ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "5. ORMì´ë€ ë¬´ì—‡ì´ë©°, ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "6. ìë°”ì—ì„œì˜ ë””ìì¸ íŒ¨í„´ ì¤‘ ê°€ì¥ ìì£¼ ì‚¬ìš©í•˜ëŠ” íŒ¨í„´ì€ ë¬´ì—‡ì´ë©°, ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "7. ìë°”ì—ì„œì˜ ìŠ¤íŠ¸ë¦¼ APIì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "8. ìë°”ì—ì„œì˜ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë°©ë²•ê³¼ Garbage Collectionì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# ì¸í„°ë·° ì§ˆë¬¸ ì‘ì„±\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"5ë…„ì°¨ ë°±ì—”ë“œ ìë°” ê°œë°œì ë©´ì ‘ì— ì‚¬ìš©í•  ì§ˆë¬¸ 8ê°œë¥¼ ì‘ì„±í•˜ì‹œì˜¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4a83e94-0581-46eb-9421-a2f4b5968042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from moviepy.editor import VideoFileClip\n",
      "\n",
      "def extract_video_metadata(video_file):\n",
      "    clip = VideoFileClip(video_file)\n",
      "    \n",
      "    metadata = {\n",
      "        'duration': clip.duration,\n",
      "        'resolution': clip.size,\n",
      "        'fps': clip.fps,\n",
      "        'codec': clip.reader.codec_type,\n",
      "        'bitrate': clip.reader.bitrate,\n",
      "        'audio_codec': clip.audio.codec,\n",
      "        'audio_bitrate': clip.audio.bitrate,\n",
      "        'audio_channels': clip.audio.nchannels\n",
      "    }\n",
      "    \n",
      "    clip.close()\n",
      "    \n",
      "    return metadata\n",
      "\n",
      "video_file = 'sample_video.mp4'\n",
      "metadata = extract_video_metadata(video_file)\n",
      "print(metadata)\n",
      "```\n",
      "\n",
      "ìœ„ì˜ ì½”ë“œëŠ” moviepy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì˜ìƒ íŒŒì¼ì˜ ë©”íƒ€ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤. ë™ì˜ìƒ íŒŒì¼ì˜ ê²½ë¡œë¥¼ `video_file` ë³€ìˆ˜ì— ì§€ì •í•˜ê³  `extract_video_metadata` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ë©”íƒ€ì •ë³´ë¥¼ ì¶”ì¶œí•œ ë’¤ ì¶œë ¥í•©ë‹ˆë‹¤. ë©”íƒ€ì •ë³´ë¡œëŠ” ë™ì˜ìƒì˜ ì¬ìƒì‹œê°„, í•´ìƒë„, í”„ë ˆì„ë ˆì´íŠ¸, ì½”ë±, ë¹„íŠ¸ë ˆì´íŠ¸, ì˜¤ë””ì˜¤ ì½”ë±, ì˜¤ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸, ì˜¤ë””ì˜¤ ì±„ë„ ìˆ˜ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë”©\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ë™ì˜ìƒ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ ê·¸ì— ëŒ€í•œ ë©”íƒ€ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì¶œë ¥í•˜ëŠ” python codeë¥¼ ì‘ì„±í•˜ì‹œì˜¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "047ffde4-2eab-492a-a62d-c0d4068d6aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¤ìŒì€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì½”ë“œ ìˆ˜ì • ì‚¬í•­ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. ì¤‘ë³µëœ ê³„ì‚°ì„ í”¼í•˜ê¸° ìœ„í•´ ì´ë¯¸ í™•ì¸í•œ ìˆ«ìë“¤ì„ ì €ì¥í•˜ëŠ” `set` ìë£Œêµ¬ì¡°ë¥¼ í™œìš©í•©ë‹ˆë‹¤.\n",
      "2. ë¶ˆí•„ìš”í•œ ë£¨í”„ë¥¼ ì¤„ì´ê¸° ìœ„í•´ í•œ ë²ˆì— ë‘ ìˆ«ìì˜ í•©ì´ `k`ê°€ ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì•„ë˜ëŠ” ìˆ˜ì •ëœ ì½”ë“œì…ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "def has_sum_k(nums: List[int], k: int) -> bool:\n",
      "    seen = set()\n",
      "    for num in nums:\n",
      "        if k - num in seen:\n",
      "            return True\n",
      "        seen.add(num)\n",
      "    return False\n",
      "```\n",
      "\n",
      "ì´ë ‡ê²Œ ìˆ˜ì •ëœ ì½”ë“œëŠ” ì‹œê°„ ë³µì¡ë„ê°€ O(n)ìœ¼ë¡œ í›¨ì”¬ ë¹ ë¥´ê²Œ ë™ì‘í•  ê²ƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë‹¤ìŒ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "from typing import List\n",
    "            \n",
    "def has_sum_k(nums: List[int], k: int) -> bool:\n",
    "    n = len(nums)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if nums[i] + nums[j] == k:\n",
    "                return True\n",
    "    return False\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96831371-594c-41c7-aa2b-e3821790ade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\">\n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "<title>One Page Website</title>\n",
      "<style>\n",
      "    body {\n",
      "        font-family: Arial, sans-serif;\n",
      "        text-align: center;\n",
      "    }\n",
      "    h1 {\n",
      "        color: #333;\n",
      "    }\n",
      "    p {\n",
      "        color: #666;\n",
      "    }\n",
      "</style>\n",
      "</head>\n",
      "<body>\n",
      "    <h1>Welcome to One Page Website</h1>\n",
      "    <p>This is a simple one page website created using HTML, CSS, and JavaScript.</p>\n",
      "    <p id=\"countdown\"></p>\n",
      "\n",
      "    <script>\n",
      "        let count = 5;\n",
      "        document.getElementById('countdown').innerText = `Redirecting in ${count} seconds...`;\n",
      "\n",
      "        setTimeout(() => {\n",
      "            window.location.href = 'https://www.example.com';\n",
      "        }, 5000);\n",
      "    </script>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# ì›¹ì‚¬ì´íŠ¸ ì½”ë”©\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"í•œ í˜ì´ì§€ì§œë¦¬ ì›¹ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•˜ì‹œì˜¤. ì´ í˜ì´ì§€ì—ëŠ” HTML, CSS, javascriptê°€ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, javascriptì˜ setTimeout() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=2048,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84116f86-56b6-417c-8435-7b69fa1c2434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íƒ€ë¸”ë¡œ:\n",
      "ë‚˜ëŠ” ë ˆì „ë“œ, ë„Œ ê·¸ëƒ¥ í—ˆì„¸\n",
      "ë„ˆì˜ ë© ì‹¤ë ¥ì€ ë””ê²Œ í—ˆì ‘í•´\n",
      "ë‚´ í™í•©ì€ ì§„ì§œ, ë„ˆì˜ëŠ” ê°€ì§œ\n",
      "ì´ ì˜ì§€ì•¼, ë„Œ ì“°ë ˆê¸°ì•¼\n",
      "\n",
      "ì´ì˜ì§€:\n",
      "ë„ˆëŠ” ê³¼ëŒ€í¬ì¥, ë‚˜ëŠ” ì‹¤ë ¥íŒŒ\n",
      "ë„Œ ê·¸ëƒ¥ ë©‹ë¶€ë¦´ ë¿ì´ë¼ê³  ë§í•´\n",
      "ë‚´ ë©ì€ ì •í†µ, ë„ˆëŠ” íŒ¨ê¸°ë§Œ\n",
      "ì´ì œ ë„Œ ë‚  ì´ê¸¸ ìˆ˜ ì—†ì„ ê±°ì•¼, ë§¨\n",
      "\n",
      "íƒ€ë¸”ë¡œ:\n",
      "ë„Œ ê·¸ì € ì½”ë¯¸ë””ì–¸, ë‚˜ëŠ” ì•„í‹°ìŠ¤íŠ¸\n",
      "ë‚´ ìŒì•…ì€ ê°ë™, ë„ˆì˜ëŠ” ë»”íˆ í‡´ë³´\n",
      "ë„ˆëŠ” ê·¸ëƒ¥ ë¬´ì§€ê°œ, ë‚œ ê²€ì€ ë¹›\n",
      "ì´ ì˜ì§€ì•¼, ë„Œ ì •ë§ ë¬´ëŠ¥ë ¥í•´\n",
      "\n",
      "ì´ì˜ì§€:\n",
      "ë‚˜ëŠ” ì§„ì§œ ë˜í¼, ë„ˆëŠ” ê·¸ëƒ¥ í‘œë¥˜\n",
      "ë‚´ ìŠ¤í‚¬ì€ ë¯¿ì–´ì§€ì§€, ë„ˆëŠ” ì‘ì‘ êº¼ì ¸\n",
      "íƒ€ë¸”ë¡œì•¼, ë„Œ ì´ê¸¸ ìˆ˜ ì—†ì–´\n",
      "ë‚˜ì˜ ë””ìŠ¤ ë©ìœ¼ë¡œ ë„ ì“°ëŸ¬ëœ¨ë ¤.\n"
     ]
    }
   ],
   "source": [
    "# ë© ë°°í‹€\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ë ˆí¼ íƒ€ë¸”ë¡œì™€ ì´ì˜ì§€ ì‚¬ì´ì˜ ë””ìŠ¤ ë©ë°°í‹€ì„ ìƒì„±í•˜ì„¸ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f538b1f-5e87-4812-8dba-dc105e4268ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì°¬ì„±: ë§ˆë¦¬í™”ë‚˜ë¥¼ í•©ë²•í™”í•˜ëŠ” ê²ƒì€ ê°œì¸ì˜ ììœ ì™€ ê¶Œë¦¬ë¥¼ ì¡´ì¤‘í•˜ëŠ” ê²ƒì´ë©°, í˜„ì¬ì˜ ê¸ˆì—°ì •ì±…ì€ ì‹¤íš¨ì„±ì´ ë–¨ì–´ì§„ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. ë˜í•œ ë§ˆë¦¬í™”ë‚˜ë¥¼ í•©ë²•í™” í•¨ìœ¼ë¡œì¨ ë¶ˆë²• ì‹œì¥ì„ ê·¼ì ˆí•˜ê³  ì„¸ê¸ˆ ìˆ˜ì…ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë°˜ëŒ€: ë§ˆë¦¬í™”ë‚˜ í•©ë²•í™”ëŠ” ì‚¬íšŒì  ì•ˆì „ê³¼ ê³µì¤‘ë³´ê±´ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆë¦¬í™”ë‚˜ì˜ ë‚¨ìš©ì´ ì¦ê°€í•  ìˆ˜ ìˆê³ , ì¤‘ë… ë¬¸ì œê°€ ì‹¬ê°í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë§ˆë¦¬í™”ë‚˜ë¥¼ í•©ë²•í™”í•œë‹¤ê³  í•´ì„œ ë¶ˆë²• ì‹œì¥ì´ ì‚¬ë¼ì§€ì§€ ì•Šì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë§ˆë¦¬í™”ë‚˜ì˜ ë¶€ì‘ìš©ì´ë‚˜ ê±´ê°• ë¬¸ì œì— ëŒ€í•œ ê³¼í•™ì ì¸ ì—°êµ¬ê°€ ë” í•„ìš”í•˜ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í† ë¡ \n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ë§ˆë¦¬í™”ë‚˜ í•©ë²•í™”ì— ëŒ€í•´ì„œ ì°¬ì„±ê³¼ ë°˜ëŒ€ë¡œ ì—­í• ì„ ë²ˆê°ˆì•„ê°€ë©´ì„œ í† ë¡ ì„ ìƒì„±í•˜ì„¸ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35556e15-24e8-4e44-ab82-e52d1ddafe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™€ìˆ˜ë§Œ ë°˜í™˜í•˜ë„ë¡ í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ë³¼ê²Œìš”.\n",
      "\n",
      "```python\n",
      "def check_odd_number(*args):\n",
      "    odd_numbers = [num for num in args if num % 2 != 0]\n",
      "    return odd_numbers\n",
      "\n",
      "result = check_odd_number(1, 5, 2, 4, 8, 10)\n",
      "print(result)\n",
      "```\n",
      "\n",
      "ì´ì œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ ê°’ë“¤ ì¤‘ í™€ìˆ˜ë§Œì„ ì¶œë ¥í•´ë³´ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# function\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Function ì—­í• ë¡œ Assistantì—ê²Œ ëª…ë ¹ì„ ì „ë‹¬\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "             \"content\": \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"accumulator\",\n",
    "            \"content\": \"ì£¼ì–´ì§„ ê°’ë“¤ì„ ëª¨ë‘ ë”í•´ì„œ ëŒë ¤ì¤ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"check_odd_number\",\n",
    "            \"content\": \"ì£¼ì–´ì§„ ìˆ˜ ì¤‘ í™€ìˆ˜ë§Œì„ ëŒë ¤ì¤ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"check_odd_number(1, 5, 2, 4, 8, 10)\"\n",
    "        },\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60a675c5-d828-46ed-b703-97804c478a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê·¸ ì‚¬ëŒì´ ë„¤ ë§ˆìŒì— ë“¤ì§€ ì•Šì•„? ê³„ì† ìŸ¤ë¥¼ ê´´ë¡­íˆê² ë‹ˆ?"
     ]
    }
   ],
   "source": [
    "# ìŠ¤íŠ¸ë¦¼\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "gen = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë¬¸ì¥ì„ ì…ë ¥ë°›ê³  ì´ë¥¼ í‘œì¤€ í•œêµ­ì–´ë¡œ ë³€ê²½í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ê·¸ ë¨¸ìŠ¤ë§ˆê°€ ë‹ˆ ë§ˆìŒì— ì•ˆë“±ë‹¤ ê·¸ ì¹´ë“œë‚˜? ê³„ì† ê¼¬ì‹œë³´ì§€?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "while True:\n",
    "    response = next(gen)\n",
    "    delta = response.choices[0].delta\n",
    "    if delta.content is not None:\n",
    "        print(delta.content, end='')\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e471425-0fad-4219-a9a3-e6b6984f5913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
