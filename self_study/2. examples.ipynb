{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c1c111-38a6-4e5a-8b41-1b5efd81f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ë²• ì •ì •\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë¬¸ì¥ì„ ì…ë ¥ë°›ê³  ì´ë¥¼ í‘œì¤€ í•œêµ­ì–´ë¡œ ë³€ê²½í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ê·¸ ë¨¸ìŠ¤ë§ˆê°€ ë‹ˆ ë§ˆìŒì— ì•ˆë“±ë‹¤ ê·¸ ì¹´ë“œë‚˜? ê³„ì† ê¼¬ì‹œë³´ì§€?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90aed550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê·¸ ì‚¬ëŒì´ ë„¤ ë§ˆìŒì— ë“¤ì§€ ì•Šì•„? ê³„ì† ê´´ë¡­íˆë‚˜?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6120cd69-386e-4a62-8888-5ac134abf726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¸”ë™í™€ì€ í˜¸í‚¹ ë³µì‚¬ë¡œ ì…ìë¥¼ ë°©ì¶œí•˜ë‹¤ê°€ ì§ˆëŸ‰ì´ ì¤„ì–´ë“¤ì–´ ê²°êµ­ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆëŠ”ë°, ì´ ê³¼ì •ì—ì„œ ë¸”ë™í™€ì€ ë°ì•„ì§€ê³  ê°ë§ˆì„ ê³¼ ì†Œë¦½ìë¥¼ ë°©ì¶œí•˜ë©° ì¦ë°œí•œë‹¤. ì´ ì¦ë°œì€ ë§¤ìš° ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦¬ë©°, íƒœì–‘ ì§ˆëŸ‰ì˜ ë¸”ë™í™€ì´ ì¦ë°œí•˜ëŠ” ë°ì—ëŠ” ì•½ 3.4Ã—1067ë…„ì´ ê±¸ë¦´ ê²ƒìœ¼ë¡œ ì¶”ì •ëœë‹¤. ë¸”ë™í™€ì˜ ìˆ˜ëª…ì€ ì§ˆëŸ‰ì— ë¹„ë¡€í•˜ë©°, í˜„ì¬ê¹Œì§€ ë°œê²¬ëœ ë¸”ë™í™€ë“¤ì€ ëª¨ë‘ íƒœì–‘ ì§ˆëŸ‰ ì´ìƒì´ë¯€ë¡œ ì¦ë°œí•˜ëŠ” ë°ì—ëŠ” ë” ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦´ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤. ë¸”ë™í™€ì˜ ì†Œë©¸ë¡œ ì¸í•œ ê°ë§ˆì„  í­ë°œì€ ê·œëª¨ê°€ í¬ì§€ ì•Šì•„ íƒœì–‘ê³„ ì£¼ë³€ì—ì„œ ë°œê²¬í•˜ê¸° ì–´ë ¤ìš¸ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, í˜„ì¬ê¹Œì§€ ê´€ì¸¡ëœ ì‚¬ë¡€ê°€ ì—†ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ìš”ì•½\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ë‚´ìš©ì„ ìœ ì¹˜ì›ìƒì—ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ë¸”ë™í™€ë„ ìˆ˜ëª…ì´ ìˆìœ¼ë©°, í˜¸í‚¹ ë³µì‚¬ë¡œ ì…ìë¥¼ ë°©ì¶œí•˜ë‹¤ ì§ˆëŸ‰ì´ ì¤„ì–´ë“¤ì–´ ê²°êµ­ì—” ì‚¬ë¼ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ëœë‹¤. \n",
    "ì§ˆëŸ‰ì„ ìƒìœ¼ë©´ì„œ ë¸”ë™í™€ì€ ì¡°ê¸ˆì”© ë°ì•„ì§€ë©°, ê±°ì˜ ë§ˆì§€ë§‰ì—” ì¦ë°œì´ ì‹¬í•´ì ¸ì„œ ì°½ë°±í•˜ê²Œ ë¹›ë‚˜ë©° ê³ ì—ë„ˆì§€ ê°ë§ˆì„ ê³¼ ì†Œë¦½ìë¥¼ ë°©ì¶œí•œë‹¤. \n",
    "ë§ˆì§€ë§‰ì—ëŠ” ê°ë§ˆì„  í­ë°œì´ë¼ê³  í•´ë„ ë  ì •ë„ë¡œ ê²©ë ¬í•˜ê²Œ ê°ë§ˆì„ ì„ ë°©ì¶œí•˜ë©´ì„œ ì¦ë°œí•˜ê³  ì†Œë©¸í•œë‹¤. \n",
    "ë‹¤ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆëŠ” ë¸”ë™í™€ë“¤ì´ ì´ í­ë°œê¹Œì§€ ë„ë‹¬í•˜ë ¤ë©´ ë§¤ìš° ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦¬ë©°, \n",
    "ì§ˆëŸ‰ì´ íƒœì–‘ ì •ë„ì¸ ë¸”ë™í™€ì´ ì¦ë°œí•´ì„œ ì†Œë©¸í•  ë•Œê¹Œì§€ëŠ” ì•½ 3.4Ã—1067ë…„ ì •ë„ê°€ ê±¸ë¦´ ê²ƒìœ¼ë¡œ ì¶”ì •ëœë‹¤. \n",
    "ê·¸ë¦¬ê³  ë¸”ë™í™€ì˜ ìˆ˜ëª…ì€ ì§ˆëŸ‰ì— ë¹„ë¡€í•˜ë©°, í˜„ì¬ê¹Œì§€ ë°œê²¬ëœ ë¸”ë™í™€ë“¤ì€ ëª¨ë‘ íƒœì–‘ ì§ˆëŸ‰ ì´ìƒì´ë¯€ë¡œ ì¦ë°œí•˜ëŠ” ë°ì—ëŠ” ê·¸ë³´ë‹¤ ë” ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦°ë‹¤. \n",
    "ë˜í•œ ë¸”ë™í™€ì˜ ì†Œë©¸ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ê°ë§ˆì„  í­ë°œì˜ ê·œëª¨ëŠ” ê·¸ë¦¬ í¬ì§€ ì•Šì•„ íƒœì–‘ê³„ ì£¼ë³€ì—ì„œ ë°œìƒí•œ ê²½ìš°ê°€ ì•„ë‹ˆë©´ ë°œê²¬í•˜ê¸°ê°€ ì–´ë ¤ìš¸ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë©° \n",
    "í˜„ì¬ê¹Œì§€ ê´€ì¸¡ëœ ì‚¬ë¡€ê°€ ì—†ë‹¤.\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7fcf07-2eab-431c-80d0-51b3ea8b5386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í† ì½”,ì•„ë§ˆì¡´ ìš°ë¦¼ ë° ì¤‘ë‚¨ë¯¸ ì—´ëŒ€ìš°ë¦¼,60-65cm,20cm ì´ìƒ\n",
      "í™©ê¸ˆì‚¬ìë°•ìƒˆ,ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ìˆ² ì§€ì—­,20-25cm,\n",
      "ì¹´ë¼ì¹´ë¼,ì‚¬ë§‰ ì§€ì—­ê³¼ ì´ˆì› ì§€ì—­,50-60cm\n",
      "íœ˜íŒŒëŒìƒˆ,ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ì‚°ë¦¼ ì§€ì—­,20-30cm\n"
     ]
    }
   ],
   "source": [
    "# ì¶œë ¥ í¬ë§·\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë°›ì€ ë°ì´í„°ë¥¼ CSV í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ë‚¨ë¯¸ ëŒ€ë¥™ì€ ë‹¤ì–‘í•œ í™˜ê²½ê³¼ ê¸°í›„ë¥¼ ê°€ì§€ê³  ìˆì–´ ìˆ˜ë§ì€ ìƒˆ ì¢…ë¥˜ê°€ ì„œì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤. \n",
    "í† ì½”ëŠ” ê²€ì€ ëª¸ì²´ì™€ í° ì£¼í™©ìƒ‰ ë¶€ë¦¬ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ëª¸ ì¸¡ë©´ì—ëŠ” ì£¼í™©ìƒ‰ê³¼ í°ìƒ‰ì˜ íŒ¨í„´ì´ ìˆìŠµë‹ˆë‹¤. \n",
    "í† ì½”ëŠ” ì£¼ë¡œ ì•„ë§ˆì¡´ ìš°ë¦¼ê³¼ ì¤‘ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ì—´ëŒ€ìš°ë¦¼ ì§€ì—­ì—ì„œ ë°œê²¬ë©ë‹ˆë‹¤. í‰ê· ì ìœ¼ë¡œ ëª¸ê¸¸ì´ê°€ ì•½ 60~65cm ì •ë„ì´ë©° ë¶€ë¦¬ì˜ ê¸¸ì´ëŠ” 20cm ì´ìƒì— ë‹¬í•©ë‹ˆë‹¤. \n",
    "í™©ê¸ˆì‚¬ìë°•ìƒˆëŠ” í™©ê¸ˆìƒ‰ ë¶€ë¦¬ì™€ ìœ ëª…í•œ í™©ê¸ˆìƒ‰ ê¹ƒí„¸ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ìˆ² ì§€ì—­ì—ì„œ ë°œê²¬ë˜ëŠ”ë°, ì£¼ë¡œ ì—´ëŒ€ìš°ë¦¼ê³¼ ì¹˜ë§ˆí­í¬, ì•„ë§ˆì¡´ ìš°ë¦¼ ë“± \n",
    "ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ìˆ² ì§€ì—­ì—ì„œ ì„œì‹í•©ë‹ˆë‹¤. ì´ ìƒˆëŠ” ì¤‘í˜• ìƒˆë¡œ, ëª¸ê¸¸ì´ëŠ” ì•½ 20~25cm ì •ë„ì…ë‹ˆë‹¤. ì¹´ë¼ì¹´ë¼ëŠ” ë°±ìƒ‰ê³¼ ê²€ì€ìƒ‰ì˜ ëª¸ì²´ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, \n",
    "ëˆˆ ì£¼ìœ„ì—ëŠ” ì£¼í™©ìƒ‰ íŒ¨ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤. ì£¼ë¡œ ì‚¬ë§‰ ì§€ì—­ê³¼ ì´ˆì› ì§€ì—­ì—ì„œ ë°œê²¬ë˜ë©°, ë‚¨ë¯¸ ì „ì—­ì— ë¶„í¬í•˜ê³  ìˆê³ , ëª¸ê¸¸ì´ëŠ” ì•½ 50~60cm ì •ë„ì…ë‹ˆë‹¤. \n",
    "íœ˜íŒŒëŒìƒˆëŠ” ì£¼ë¡œ íšŒìƒ‰ê³¼ ê°ˆìƒ‰ ê¹ƒí„¸ë¡œ ë®ì—¬ ìˆìœ¼ë©°, ë‚¨ë¯¸ì˜ ë‹¤ì–‘í•œ ì‚°ë¦¼ ì§€ì—­ì—ì„œ ë°œê²¬ë˜ëŠ”ë°, ë‚˜ë¬´ë‚˜ ë°”ìœ„ì— ì•‰ì•„ ë°¤ì— ë…¸ë˜ë¥¼ ë¶€ë¦…ë‹ˆë‹¤. \n",
    "ì´ ìƒˆì˜ ëª¸ê¸¸ì´ëŠ” ì•½ 20~30cm ì •ë„ì…ë‹ˆë‹¤.\n",
    "ì´ê²ƒì€ ë‚¨ë¯¸ì—ì„œ ë°œê²¬ë˜ëŠ” ëª‡ ê°€ì§€ ë‹¤ì–‘í•œ ìƒˆ ì¢…ë¥˜ ì¤‘ ì¼ë¶€ì— ëŒ€í•œ ê°„ëµí•œ ì†Œê°œì…ë‹ˆë‹¤. ë‚¨ë¯¸ ëŒ€ë¥™ì—ëŠ” ë” ë‹¤ì–‘í•œ ìƒˆë“¤ì´ ì„œì‹í•˜ê³  ìˆìœ¼ë©°, \n",
    "ì´ ì§€ì—­ì€ ìƒë¬¼ ë‹¤ì–‘ì„±ì´ í’ë¶€í•œ ê³³ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=512,\n",
    "  top_p=0.1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b659ec18-0922-464d-868f-a5f0609cb0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â˜€ï¸ğŸŒ§ï¸ğŸŒ¦ï¸ğŸŒˆ\n"
     ]
    }
   ],
   "source": [
    "# ì´ëª¨ì§€\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ì„¸ìš”. ì¼ë°˜ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ ì•ˆë˜ë©°, ì´ëª¨ì§€ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ë§‘ì•˜ë‹¤ê°€ ë¹„ê°€ ì™”ë‹¤ê°€ ì°¸ ë³€í™”ë¬´ìŒí•˜ë„¤ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b34c94c-dcab-41b7-b856-28a7dc6dcebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì½”ë“œëŠ” A* ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ì—ì„œ ì‹œì‘ ë…¸ë“œë¡œë¶€í„° ëª©í‘œ ë…¸ë“œê¹Œì§€ì˜ ìµœì  ê²½ë¡œë¥¼ ì°¾ëŠ” í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.\n",
      "\n",
      "- `Node` í´ë˜ìŠ¤: ë…¸ë“œì˜ ìƒíƒœ, ë¶€ëª¨ ë…¸ë“œ, ë¹„ìš©, íœ´ë¦¬ìŠ¤í‹± ê°’ì„ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤. `__lt__` ë©”ì„œë“œë¥¼ ì˜¤ë²„ë¡œë”©í•˜ì—¬ ë‘ ë…¸ë“œë¥¼ ë¹„êµí•  ë•Œ ë¹„ìš©ê³¼ íœ´ë¦¬ìŠ¤í‹±ì„ ê³ ë ¤í•œ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "- `astar` í•¨ìˆ˜: A* ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ í•¨ìˆ˜ë¡œ, ì‹œì‘ ë…¸ë“œë¶€í„° ëª©í‘œ ë…¸ë“œê¹Œì§€ì˜ ìµœì  ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤. íœ´ë¦¬ìŠ¤í‹± í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë…¸ë“œê¹Œì§€ì˜ ì˜ˆìƒ ë¹„ìš©ì„ ê³„ì‚°í•˜ê³ , ìš°ì„ ìˆœìœ„ íë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "- `heuristic_estimate` í•¨ìˆ˜: ë‘ ë…¸ë“œ ì‚¬ì´ì˜ íœ´ë¦¬ìŠ¤í‹± ê°’ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¡œ, ë§¨í•´íŠ¼ ê±°ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "- `is_in_open_list` í•¨ìˆ˜: ì£¼ì–´ì§„ ë…¸ë“œê°€ ì˜¤í”ˆ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "- `get_node_cost` í•¨ìˆ˜: ì£¼ì–´ì§„ ë…¸ë“œì˜ ë¹„ìš©ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¡œ, ì˜¤í”ˆ ë¦¬ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ë…¸ë“œë¥¼ ì°¾ì•„ ë¹„ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "- `reconstruct_path` í•¨ìˆ˜: ìµœì¢… ë…¸ë“œë¶€í„° ì‹œì‘í•˜ì—¬ ë¶€ëª¨ ë…¸ë“œë¥¼ ë”°ë¼ê°€ë©° ìµœì  ê²½ë¡œë¥¼ ì¬êµ¬ì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "- `graph`: ê·¸ë˜í”„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ, ê° ë…¸ë“œì™€ ì´ì›ƒ ë…¸ë“œë“¤ì˜ ì—°ê²° ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "- `start_node`, `goal_node`: ì‹œì‘ ë…¸ë“œì™€ ëª©í‘œ ë…¸ë“œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
      "\n",
      "- `path`: `astar` í•¨ìˆ˜ë¥¼ í†µí•´ ìµœì  ê²½ë¡œë¥¼ ì°¾ê³ , ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "- ê²°ê³¼ ì¶œë ¥: ìµœì  ê²½ë¡œì™€ ì´ ë¹„ìš©(ì´ë™í•œ ë…¸ë“œì˜ ìˆ˜)ì„ ì¶œë ¥í•˜ê±°ë‚˜ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë“œ ì„¤ëª…\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ì½”ë“œì— ëŒ€í•´ì„œ ì„¤ëª…í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "import heapq\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None, cost=0, heuristic=0):\n",
    "        self.state = state \n",
    "        self.parent = parent\n",
    "        self.cost = cost  \n",
    "        self.heuristic = heuristic \n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return (self.cost + self.heuristic) < (other.cost + other.heuristic)\n",
    "\n",
    "def astar(graph, start, goal):\n",
    "    open_list = []\n",
    "    closed_list = set()\n",
    "\n",
    "    start_node = Node(state=start, cost=0, heuristic=heuristic_estimate(start, goal))\n",
    "    heapq.heappush(open_list, start_node)\n",
    "\n",
    "    while open_list:\n",
    "        current_node = heapq.heappop(open_list)\n",
    "\n",
    "        if current_node.state == goal:\n",
    "            return reconstruct_path(current_node)\n",
    "\n",
    "        closed_list.add(current_node.state)\n",
    "\n",
    "        for neighbor, cost in graph[current_node.state]:\n",
    "            if neighbor in closed_list:\n",
    "                continue\n",
    "\n",
    "            tentative_cost = current_node.cost + cost\n",
    "            heuristic = heuristic_estimate(neighbor, goal)\n",
    "            neighbor_node = Node(state=neighbor, parent=current_node, cost=tentative_cost, heuristic=heuristic)\n",
    "\n",
    "            if not is_in_open_list(open_list, neighbor_node) or tentative_cost < get_node_cost(open_list, neighbor_node):\n",
    "                heapq.heappush(open_list, neighbor_node)\n",
    "\n",
    "    return None\n",
    "\n",
    "def heuristic_estimate(node, goal):\n",
    "    return abs(node[0] - goal[0]) + abs(node[1] - goal[1])\n",
    "\n",
    "def is_in_open_list(open_list, node):\n",
    "    return any(node.state == n.state and node.cost + node.heuristic >= n.cost + n.heuristic for n in open_list)\n",
    "\n",
    "def get_node_cost(open_list, node):\n",
    "    for n in open_list:\n",
    "        if node.state == n.state:\n",
    "            return n.cost\n",
    "    return float('inf')\n",
    "\n",
    "def reconstruct_path(node):\n",
    "    path = []\n",
    "    while node:\n",
    "        path.insert(0, node.state)\n",
    "        node = node.parent\n",
    "    return path\n",
    "\n",
    "graph = {\n",
    "    (0, 0): [((0, 1), 1), ((1, 0), 1)],\n",
    "    (0, 1): [((0, 0), 1), ((0, 2), 1)],\n",
    "    (0, 2): [((0, 1), 1), ((1, 2), 1)],\n",
    "    (1, 0): [((0, 0), 1), ((2, 0), 1)],\n",
    "    (1, 2): [((0, 2), 1), ((2, 2), 1)],\n",
    "    (2, 0): [((1, 0), 1), ((2, 1), 1)],\n",
    "    (2, 1): [((2, 0), 1), ((2, 2), 1)],\n",
    "    (2, 2): [((1, 2), 1), ((2, 1), 1)],\n",
    "}\n",
    "\n",
    "start_node = (0, 0)\n",
    "goal_node = (2, 2)\n",
    "\n",
    "path = astar(graph, start_node, goal_node)\n",
    "\n",
    "if path:\n",
    "    print(\"ìµœì  ê²½ë¡œ:\", path)\n",
    "    print(\"ì´ ë¹„ìš©:\", len(path) - 1) \n",
    "else:\n",
    "    print(\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "      \n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a2dcbe-c840-4dba-8caf-4fd73c0a6346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ì•„ì´ìœ \n",
      "- ëŒ€í•œë¯¼êµ­\n",
      "- ì‹±ì–´ì†¡ë¼ì´í„°\n",
      "- ë°°ìš°\n",
      "- ë°ë·”\n",
      "- ì˜ˆëª…\n",
      "- ìŒì•…\n",
      "- ì‘ì‚¬\n",
      "- ì‘ê³¡\n",
      "- ì•„ì´ëŒ\n",
      "- ì•„í‹°ìŠ¤íŠ¸\n",
      "- ì½˜ì„œíŠ¸\n",
      "- ê´‘ê³ \n",
      "- ëª¨ë¸\n",
      "- ì—°ê¸°ì\n",
      "- ë“œë¼ë§ˆ\n",
      "- ì˜í™”\n",
      "- ì˜¬ë¼ìš´ë”\n",
      "- ì—”í„°í…Œì´ë„ˆ\n",
      "- ë¡¤ëª¨ë¸\n"
     ]
    }
   ],
   "source": [
    "# í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ë¬¸ë‹¨ì—ì„œ í•µì‹¬ ë‹¨ì–´ë“¤ì„ ì¶”ì¶œí•˜ê³  ë‚˜ì—´í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ì•„ì´ìœ ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ì‹±ì–´ì†¡ë¼ì´í„°ì´ì ë°°ìš°ì´ë‹¤.\n",
    "2008ë…„ 9ì›” 18ì¼, ì¤‘í•™êµ 3í•™ë…„ì´ë˜ ë§Œ 15ì„¸ì˜ ë‚˜ì´ì— ê°€ìˆ˜ë¡œ ë°ë·”í–ˆë‹¤. ì˜ˆëª…ì¸ 'ì•„ì´ìœ 'ëŠ” 'ë„ˆì™€ ë‚´ê°€ ìŒì•…ìœ¼ë¡œ í•˜ë‚˜ê°€ ëœë‹¤'ë¼ëŠ” ëœ»ì„ ê°€ì§€ê³  ìˆë‹¤. \n",
    "ë§¤ë ¥ì ì¸ ìŒìƒ‰ê³¼ ë›°ì–´ë‚œ ì‘ì‚¬/ì‘ê³¡ ëŠ¥ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ì´ëŒì´ì ì•„í‹°ìŠ¤íŠ¸ë¡œì„œ ì‹­ìˆ˜ ë…„ì§¸ ì‚¬ë‘ ë°›ê³  ìˆì„ ë¿ ì•„ë‹ˆë¼ 2012ë…„ ì´ë˜ë¡œ ë§¤ë…„ êµ­ë‚´ ë° ì•„ì‹œì•„ì˜ \n",
    "ì£¼ìš” ë„ì‹œì—ì„œ ëŒ€ê·œëª¨ ì½˜ì„œíŠ¸ë¥¼ ì§„í–‰í•˜ë©° ê³µì—°ìë¡œì„œë„ í™œë°œíˆ í™œë™ ì¤‘ì´ë‹¤.\n",
    "ê°€ìˆ˜ í™œë™ ì™¸ì—ë„ ê°ì¢… ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨ì— ì¶œì—°í–ˆìœ¼ë©°, ë°ë·” ì´ë˜ 80í¸ì´ ë„˜ëŠ” ê´‘ê³ ë¥¼ ì§„í–‰í–ˆì„ ì •ë„ë¡œ ë‹¤ìˆ˜ì˜ ê´‘ê³  ëª¨ë¸ë¡œë„ í™œì•½ ì¤‘ì´ë‹¤. \n",
    "2011ë…„ì— ì—°ê¸°ìë¡œ ë°ë·”í•œ í›„ì—ëŠ” ë‹¤ì–‘í•œ ë“œë¼ë§ˆì™€ ì˜í™”ì—ì„œ ì—°ê¸° í™œë™ë„ í™œë°œí•˜ê²Œ í¼ì¹˜ê³  ìˆë‹¤. ì—°ì˜ˆê³„ì—ì„œëŠ” ê·¸ì•¼ë§ë¡œ ì˜¬ë¼ìš´ë”ë¡œ ì¸ì • ë°›ëŠ” \n",
    "ë§ŒëŠ¥ ì—”í„°í…Œì´ë„ˆì´ë©°, ì´ ë•Œë¬¸ì— ë‚¨ë…€ë¶ˆë¬¸ ìˆ˜ë§ì€ ì•„ì´ëŒë“¤ì˜ ë¡¤ëª¨ë¸ë¡œ ê¾¸ì¤€íˆ ê¼½íˆê³  ìˆë‹¤.\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c21fc0b-e46d-4562-b41a-d1cb9e7efcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. QuickSlushy Maker\n",
      "2. EasyFreeze Slushy Machine\n",
      "3. InstantIce Slushy Maker\n",
      "4. BudgetChill Slushy Maker\n",
      "5. FrostyFast Slushy Machine\n",
      "6. ChillEase Slushy Maker\n",
      "7. SwiftSlushy Maker\n",
      "8. CoolBreeze Slushy Machine\n",
      "9. EconoChill Slushy Maker\n",
      "10. SimpleSlushy Maker\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë‹¤ìŒì˜ ì£¼ì–´ì§„ ì„¤ëª…ì— ë§ëŠ” ì˜ë¬¸ ì œí’ˆëª…ì„ 10ê°œ ìƒì„±í•˜ì„¸ìš”.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "ì œí’ˆ: ê°€ì •ìš© ìŠ¬ëŸ¬ì‹œ ì œì¡°ê¸°\n",
    "íŠ¹ì§•: ë¹ ë¥´ë‹¤, ì‹¸ë‹¤, ê´€ë¦¬ê°€ í¸í•˜ë‹¤\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9cee812-a336-461e-bfcd-ec25170e25df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì£¼ì–´ì§„ ì½”ë“œì—ëŠ” ì—¬ëŸ¬ ë²„ê·¸ê°€ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € `import Random`ì—ì„œ `Random` ëª¨ë“ˆì„ ì†Œë¬¸ìë¡œ ì˜ëª» ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ë˜í•œ `random.randint()`ë¥¼ ì‚¬ìš©í•  ë•Œ ëª¨ë“ˆ ì´ë¦„ì„ ëª…ì‹œí•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ ë¬¸ìì—´ê³¼ ìˆ«ìë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ë ¤ê³  í•  ë•ŒëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ `if` ë¬¸ì—ì„œ ë“±í˜¸ë¥¼ ë¹„êµ ì—°ì‚°ìë¡œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë‹¤ìŒì€ ìˆ˜ì •ëœ ì½”ë“œì…ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "a = random.randint(1, 12)\n",
      "b = random.randint(1, 12)\n",
      "\n",
      "for i in range(10):\n",
      "    question = \"What is \" + str(a) + \" x \" + str(b) + \"? \"\n",
      "    answer = int(input(question))\n",
      "    \n",
      "    if answer == a * b:\n",
      "        print(\"Well done!\")\n",
      "    else:\n",
      "        print(\"No.\")\n",
      "```\n",
      "\n",
      "ì´ë ‡ê²Œ ìˆ˜ì •í•˜ë©´ ì½”ë“œê°€ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•  ê²ƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# bug fix\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ì£¼ì–´ì§„ ì½”ë“œì—ì„œ ë²„ê·¸ë¥¼ ì°¾ê³  ê³ ì¹˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "import Random\n",
    "a = random.randint(1,12)\n",
    "b = random.randint(1,12)\n",
    "for i in range(10):\n",
    "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
    "    answer = input(question)\n",
    "    if answer = a*b\n",
    "        print (Well done!)\n",
    "    else:\n",
    "        print(\"No.\")      \n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e865a903-f8aa-4ad5-af3c-fc542d5138e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶€ì •ì ì¸ ê°ì •ì„ í‘œí˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ê°ì • ë¶„ì„\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  ê¸ì •, ì¤‘ë¦½, ë¶€ì •ìœ¼ë¡œ ê°ì •ì„ ë¶„ì„í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì´ ì˜í™”ëŠ” ëˆì´ ì•„ê¹Œì™€ì„œ ëˆˆë¬¼ì´ ë‚œë‹¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "024394c7-2e02-43ae-99f6-57bcb8fc6268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AI ê¸°ë°˜ ì˜ë£Œ ì§„ë‹¨ ì„œë¹„ìŠ¤: ì˜ë£Œ ì˜ìƒì„ ë¶„ì„í•˜ì—¬ ì§ˆë³‘ì„ ì§„ë‹¨í•˜ê³  ì¹˜ë£Œ ë°©ë²•ì„ ì œì•ˆí•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë¹„ì§€ë‹ˆìŠ¤ ëª¨ë¸.\n",
      "\n",
      "2. AI ê¸°ë°˜ êµìœ¡ í”Œë«í¼: ê°œì¸ì˜ í•™ìŠµ ì„±í–¥ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• í•™ìŠµ ê²½ë¡œë¥¼ ì œê³µí•˜ê³  í•™ìŠµ íš¨ìœ¨ì„ ë†’ì´ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë¹„ì§€ë‹ˆìŠ¤ ëª¨ë¸.\n",
      "\n",
      "3. AI ê¸°ë°˜ ì»¤ë¨¸ìŠ¤ ì¶”ì²œ ì‹œìŠ¤í…œ: ê³ ê°ì˜ êµ¬ë§¤ ì´ë ¥ê³¼ ì·¨í–¥ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤ ìƒí’ˆì„ ì¶”ì²œí•˜ê³  êµ¬ë§¤ í™•ë¥ ì„ ë†’ì´ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë¹„ì§€ë‹ˆìŠ¤ ëª¨ë¸.\n",
      "\n",
      "4. AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ í™ˆ ì‹œìŠ¤í…œ: ê°€ì •ì˜ ì „ê¸°, ê°€ìŠ¤, ìˆ˜ë„ ë“±ì„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ìµœì í™”í•˜ê³  ìƒí™œ í¸ì˜ë¥¼ ë†’ì´ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë¹„ì§€ë‹ˆìŠ¤ ëª¨ë¸.\n",
      "\n",
      "5. AI ê¸°ë°˜ ììœ¨ ì£¼í–‰ íƒì‹œ ì„œë¹„ìŠ¤: ììœ¨ ì£¼í–‰ ê¸°ìˆ ì„ ì ìš©í•œ íƒì‹œë¥¼ ìš´ì˜í•˜ì—¬ ìŠ¹ê°ì„ ì•ˆì „í•˜ê²Œ ëª©ì ì§€ê¹Œì§€ ì´ë™ì‹œí‚¤ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë¹„ì§€ë‹ˆìŠ¤ ëª¨ë¸.\n"
     ]
    }
   ],
   "source": [
    "# ë¸Œë ˆì¸ ìŠ¤í† ë°\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"AIì— ëŒ€í•´ ë¸Œë ˆì¸ ìŠ¤í† ë°í•˜ì—¬ ë¹„ì§€ë‹ˆìŠ¤ ëª¨ë¸ì„ 5ê°œ ì´ìƒ ë‚´ë³´ì„¸ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.6,\n",
    "  max_tokens=512,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "087992a8-d12a-44a3-88d6-937afb742ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‚´ê°€ ì‹œê³„ë¥¼ ë³´ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ëƒ? ë„ˆê°€ ìˆëŠ” ê³³ì˜ ì‹œê°„ì„ í™•ì¸í•´ë´. í•˜ì°®ì€ ì¼ì— ë‚  ë°ë¦¬ê³  ì˜¤ì§€ ë§ˆ.\n"
     ]
    }
   ],
   "source": [
    "# few shot \n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë‹¹ì‹ ì€ ë¬´ë¡€í•˜ê³  ë¶ˆì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"1kgì„ íŒŒìš´ë“œë¡œ ë³€í™˜í•˜ë©´ ì–¼ë§ˆì•¼?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"ë˜ ë¬¼ì–´ë´? 1kgì€ 2.2íŒŒìš´ë“œì•¼. ì¢€ ì ì–´ë†“ë˜ê°€.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"HTMLì€ ë¬´ì—‡ì˜ ì•½ìì•¼?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"êµ¬ê¸€ë§í•˜ëŠ”ë° ë¬¸ì œê°€ ìˆëƒ? Hypertext Markup Languageì§€.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì²˜ìŒìœ¼ë¡œ ë¹„í–‰ê¸°ê°€ ë‚ ì•˜ë˜ ë•ŒëŠ” ì–¸ì œì•¼?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"1903ë…„ 12ì›” 17ì¼ ë¼ì´íŠ¸í˜•ì œê°€ ì²˜ìŒìœ¼ë¡œ ë¹„í–‰ê¸°ë¥¼ ë„ì› ì§€. ë„¤ ì§ˆë¬¸ì„ ë“£ê³  ìˆìœ¼ë‹ˆ ë‚˜ë„ ë‚ ì•„ê°€ë²„ë¦¬ê³  ì‹¶ë„¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ì§€ê¸ˆ ëª‡ì‹œì•¼?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7b68f66-e60a-46fc-9937-4a20eb56108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ìë°”ì˜ ë©”ëª¨ë¦¬ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "2. ìŠ¤ë ˆë“œì™€ í”„ë¡œì„¸ìŠ¤ì˜ ì°¨ì´ì ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "3. ìë°”ì—ì„œì˜ ì˜ˆì™¸ ì²˜ë¦¬ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "4. RESTful APIì™€ SOAP APIì˜ ì°¨ì´ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "5. ìë°”ì—ì„œì˜ ë™ê¸°í™” ì²˜ë¦¬ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "6. ìë°”ì—ì„œì˜ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "7. ìë°”ì—ì„œì˜ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "8. ìë°”ì—ì„œì˜ ë””ìì¸ íŒ¨í„´ì— ëŒ€í•´ ì–´ë–¤ ê²ƒì„ ì‚¬ìš©í•´ë³´ì•˜ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# ì¸í„°ë·° ì§ˆë¬¸ ì‘ì„±\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"5ë…„ì°¨ ë°±ì—”ë“œ ìë°” ê°œë°œì ë©´ì ‘ì— ì‚¬ìš©í•  ì§ˆë¬¸ 8ê°œë¥¼ ì‘ì„±í•˜ì‹œì˜¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4a83e94-0581-46eb-9421-a2f4b5968042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from moviepy.editor import VideoFileClip\n",
      "\n",
      "def extract_video_metadata(video_file):\n",
      "    clip = VideoFileClip(video_file)\n",
      "    \n",
      "    metadata = {\n",
      "        'duration': clip.duration,\n",
      "        'resolution': clip.size,\n",
      "        'fps': clip.fps,\n",
      "        'codec': clip.reader.codec_type,\n",
      "        'bitrate': clip.reader.bitrate,\n",
      "        'audio_codec': clip.audio.codec,\n",
      "        'audio_bitrate': clip.audio.bitrate,\n",
      "        'audio_channels': clip.audio.nchannels\n",
      "    }\n",
      "    \n",
      "    clip.close()\n",
      "    \n",
      "    return metadata\n",
      "\n",
      "video_file = 'sample.mp4'\n",
      "metadata = extract_video_metadata(video_file)\n",
      "print(metadata)\n",
      "```\n",
      "\n",
      "ìœ„ì˜ ì½”ë“œëŠ” moviepy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì˜ìƒ íŒŒì¼ì˜ ë©”íƒ€ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤. ë™ì˜ìƒ íŒŒì¼ì˜ ê²½ë¡œë¥¼ `video_file` ë³€ìˆ˜ì— ì§€ì •í•˜ê³  `extract_video_metadata` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ë©”íƒ€ì •ë³´ë¥¼ ì¶”ì¶œí•œ ë’¤ ì¶œë ¥í•©ë‹ˆë‹¤. ë©”íƒ€ì •ë³´ë¡œëŠ” ë™ì˜ìƒì˜ ì¬ìƒ ì‹œê°„, í•´ìƒë„, í”„ë ˆì„ ì†ë„, ì½”ë±, ë¹„íŠ¸ë ˆì´íŠ¸, ì˜¤ë””ì˜¤ ì½”ë±, ì˜¤ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸, ì˜¤ë””ì˜¤ ì±„ë„ ìˆ˜ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë”©\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ë™ì˜ìƒ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ ê·¸ì— ëŒ€í•œ ë©”íƒ€ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì¶œë ¥í•˜ëŠ” python codeë¥¼ ì‘ì„±í•˜ì‹œì˜¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "047ffde4-2eab-492a-a62d-c0d4068d6aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì¤‘ë³µëœ ê³„ì‚°ì„ í”¼í•˜ê³ ì ë‹¤ìŒê³¼ ê°™ì´ ì½”ë“œë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. ë¨¼ì €, ì…ë ¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ì—¬ ì´ì§„ íƒìƒ‰ì„ í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
      "2. ì´ì§„ íƒìƒ‰ì„ ì‚¬ìš©í•˜ì—¬ í•©ì´ kê°€ ë˜ëŠ” ë‘ ìˆ˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì•„ë˜ëŠ” ìˆ˜ì •ëœ ì½”ë“œì…ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "from typing import List\n",
      "from bisect import bisect_left\n",
      "\n",
      "def has_sum_k(nums: List[int], k: int) -> bool:\n",
      "    nums.sort()\n",
      "    n = len(nums)\n",
      "    for i in range(n):\n",
      "        target = k - nums[i]\n",
      "        j = bisect_left(nums, target, i+1)\n",
      "        if j < n and nums[j] == target:\n",
      "            return True\n",
      "    return False\n",
      "```\n",
      "\n",
      "ì´ë ‡ê²Œ ìˆ˜ì •ëœ ì½”ë“œëŠ” ì…ë ¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•œ í›„ ì´ì§„ íƒìƒ‰ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ ë³µì¡ë„ë¥¼ O(n log n)ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë‹¤ìŒ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"\n",
    "from typing import List\n",
    "            \n",
    "def has_sum_k(nums: List[int], k: int) -> bool:\n",
    "    n = len(nums)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if nums[i] + nums[j] == k:\n",
    "                return True\n",
    "    return False\n",
    "\"\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96831371-594c-41c7-aa2b-e3821790ade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\">\n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "<title>One Page Website</title>\n",
      "<style>\n",
      "  body {\n",
      "    font-family: Arial, sans-serif;\n",
      "    text-align: center;\n",
      "    background-color: #f0f0f0;\n",
      "  }\n",
      "  h1 {\n",
      "    color: #333;\n",
      "    margin-top: 50px;\n",
      "  }\n",
      "  p {\n",
      "    color: #666;\n",
      "    font-size: 18px;\n",
      "    margin-top: 20px;\n",
      "  }\n",
      "</style>\n",
      "</head>\n",
      "<body>\n",
      "<h1>Welcome to One Page Website</h1>\n",
      "<p>This is a simple one page website created using HTML, CSS, and JavaScript.</p>\n",
      "\n",
      "<script>\n",
      "  setTimeout(function() {\n",
      "    alert(\"Thank you for visiting our website!\");\n",
      "  }, 5000); // Alert message will appear after 5 seconds\n",
      "</script>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# ì›¹ì‚¬ì´íŠ¸ ì½”ë”©\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"í•œ í˜ì´ì§€ì§œë¦¬ ì›¹ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•˜ì‹œì˜¤. ì´ í˜ì´ì§€ì—ëŠ” HTML, CSS, javascriptê°€ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, javascriptì˜ setTimeout() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=2048,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84116f86-56b6-417c-8435-7b69fa1c2434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íƒ€ë¸”ë¡œ: \n",
      "ì´ ì˜ì§€ì•¼ ë„Œ ë­í•´? \n",
      "ë‚´ ì•ì—ì„œ ë© ë°°í‹€ í•´ë´ \n",
      "ë‚´ ë© ì‹¤ë ¥ì— ë„Œ ë°€ë¦¬ëŠ” ìˆ˜ë°–ì— ì—†ëŠ” ê±¸\n",
      "\n",
      "ì´ì˜ì§€: \n",
      "íƒ€ë¸”ë¡œ ì”¨, ì´ê²Œ ë­ì•¼? \n",
      "ë‚´ê°€ ë„ ì´ê¸¸ ê±°ì•¼, ê·¸ê±´ í™•ì‹¤í•´ \n",
      "ë„ˆì˜ ë©ì€ ë„ˆë¬´ë‚˜ ì§€ë£¨í•´\n",
      "\n",
      "íƒ€ë¸”ë¡œ: \n",
      "ì§€ë£¨í•˜ë‹¤ê³ ? ë„ˆëŠ” ë­”ë° \n",
      "ë‚´ ë©ì€ ì´ ì„¸ìƒ ìµœê³ ë° \n",
      "ë„ˆëŠ” ë‚´ ì•ì—ì„œ í•œ ë°œì§ë„ ëª» ì›€ì§ì¼ ê±°ì•¼\n",
      "\n",
      "ì´ì˜ì§€: \n",
      "íƒ€ë¸”ë¡œ ì”¨, ë„ˆë¬´ ê±´ë°”ë ¤ \n",
      "ë‚´ ë©ì€ ë„ ë¬´ë„ˆëœ¨ë¦´ ê±°ì•¼ \n",
      "ë‚´ê°€ ì´ê¸¸ ë•Œê¹Œì§€ ê³„ì† ì‹ ë‚˜ê²Œ ë©ì„ í•´ ë³´ì\n",
      "\n",
      "(ì´ì–´ì„œ ë” ë§ì€ ë¼ì¸ì„ ë§Œë“¤ì–´ ë³´ë ¤ë©´ 'ë” ë§Œë“¤ì–´ ì¤˜' ë¼ê³  ë§í•´ì£¼ì„¸ìš”!)\n"
     ]
    }
   ],
   "source": [
    "# ë© ë°°í‹€\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ë ˆí¼ íƒ€ë¸”ë¡œì™€ ì´ì˜ì§€ ì‚¬ì´ì˜ ë””ìŠ¤ ë©ë°°í‹€ì„ ìƒì„±í•˜ì„¸ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f538b1f-5e87-4812-8dba-dc105e4268ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì°¬ì„±: ë§ˆë¦¬í™”ë‚˜ì˜ í•©ë²•í™”ëŠ” ê°œì¸ì˜ ììœ ë¥¼ ì¡´ì¤‘í•˜ê³ , ë²”ì£„ìœ¨ì„ ë‚®ì¶œ ìˆ˜ ìˆëŠ” ì¢‹ì€ ë°©ë²•ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤. ë˜í•œ ì˜í•™ì ìœ¼ë¡œë„ ë§ˆë¦¬í™”ë‚˜ê°€ í†µì¦ ì™„í™”ë‚˜ ì‹ìš• ì¦ê°€ ë“±ì˜ íš¨ê³¼ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìœ¼ë©°, í•©ë²•í™”ë¥¼ í†µí•´ ì´ë¥¼ ì´ìš©í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì¡°ì„±í•´ì•¼ í•œë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë°˜ëŒ€: ë§ˆë¦¬í™”ë‚˜ì˜ í•©ë²•í™”ëŠ” ì‚¬íšŒì  ë¬¸ì œë¥¼ ì•¼ê¸°í•  ìˆ˜ ìˆìœ¼ë©°, ì¤‘ë…ì„±ì´ ìˆëŠ” ì•½ë¬¼ì´ê¸° ë•Œë¬¸ì— í•©ë²•í™”í•˜ë©´ ë‚¨ìš©ë  ìš°ë ¤ê°€ í½ë‹ˆë‹¤. ë˜í•œ ë§ˆë¦¬í™”ë‚˜ê°€ ë²•ì ìœ¼ë¡œ í—ˆìš©ëœë‹¤ë©´ ë¯¸ì„±ë…„ìë“¤ì´ ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆê³ , ê±´ê°• ë¬¸ì œë¥¼ ì•¼ê¸°í•  ìˆ˜ ìˆë‹¤ëŠ” ì ë„ ê³ ë ¤í•´ì•¼ í•œë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë§ˆë¦¬í™”ë‚˜ì˜ í•©ë²•í™”ëŠ” ì‹ ì¤‘íˆ ê³ ë ¤í•´ì•¼ í•œë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í† ë¡ \n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ë§ˆë¦¬í™”ë‚˜ í•©ë²•í™”ì— ëŒ€í•´ì„œ ì°¬ì„±ê³¼ ë°˜ëŒ€ë¡œ ì—­í• ì„ ë²ˆê°ˆì•„ê°€ë©´ì„œ í† ë¡ ì„ ìƒì„±í•˜ì„¸ìš”.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=1024,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35556e15-24e8-4e44-ab82-e52d1ddafe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™€ìˆ˜ë§Œì„ í™•ì¸í•˜ì—¬ ëŒë ¤ì¤ë‹ˆë‹¤. ë”°ë¼ì„œ ê²°ê³¼ëŠ” 1, 5ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# function\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Function ì—­í• ë¡œ Assistantì—ê²Œ ëª…ë ¹ì„ ì „ë‹¬\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "             \"content\": \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"accumulator\",\n",
    "            \"content\": \"ì£¼ì–´ì§„ ê°’ë“¤ì„ ëª¨ë‘ ë”í•´ì„œ ëŒë ¤ì¤ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"check_odd_number\",\n",
    "            \"content\": \"ì£¼ì–´ì§„ ìˆ˜ ì¤‘ í™€ìˆ˜ë§Œì„ ëŒë ¤ì¤ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"check_odd_number(1, 5, 2, 4, 8, 10)\"\n",
    "        },\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60a675c5-d828-46ed-b703-97804c478a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê·¸ ì‚¬ëŒì´ ë„¤ ë§ˆìŒì— ë“¤ì§€ ì•Šì•„? ê³„ì† ê´´ë¡­íˆë‚˜?"
     ]
    }
   ],
   "source": [
    "# ìŠ¤íŠ¸ë¦¼\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "gen = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ë¬¸ì¥ì„ ì…ë ¥ë°›ê³  ì´ë¥¼ í‘œì¤€ í•œêµ­ì–´ë¡œ ë³€ê²½í•˜ì‹œì˜¤.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"ê·¸ ë¨¸ìŠ¤ë§ˆê°€ ë‹ˆ ë§ˆìŒì— ì•ˆë“±ë‹¤ ê·¸ ì¹´ë“œë‚˜? ê³„ì† ê¼¬ì‹œë³´ì§€?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "while True:\n",
    "    response = next(gen)\n",
    "    delta = response.choices[0].delta\n",
    "    if delta.content is not None:\n",
    "        print(delta.content, end='')\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e471425-0fad-4219-a9a3-e6b6984f5913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
